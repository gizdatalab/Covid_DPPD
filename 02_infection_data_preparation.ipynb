{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rki_raw = pd.read_csv('https://www.arcgis.com/sharing/rest/content/items/f10774f1c63e40168479a1feb6c7ca74/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rki_raw.rename(columns={'IdLandkreis':'districtId'}, inplace=True)\n",
    "rki_raw.loc[rki_raw['Bundesland']=='Berlin','districtId'] = 11000 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rki_infect = rki_raw[rki_raw.NeuerFall >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rki_deaths = rki_raw[rki_raw.NeuerTodesfall >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns needed for both cases and deaths\n",
    "cols = ['districtId','Altersgruppe','Geschlecht','Meldedatum']#Melde statt Ref\n",
    "#Landkreisname ist schon in static data, Bundesland brauchen wir wohl nicht und ist im AGS drin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggr_reports(df, count_col):\n",
    "    \n",
    "    df = df[cols+[count_col]].copy()\n",
    "    #prepare datetime columns\n",
    "    df['Meldedatum'] = pd.to_datetime(df['Meldedatum'])\n",
    "    df['week_no'] = df['Meldedatum'].dt.week\n",
    "    \n",
    "    #get special columns for age cohorts and genders\n",
    "    for col in ['Geschlecht', 'Altersgruppe']:\n",
    "        dummy_df = pd.get_dummies(df[col], prefix=col, drop_first=False)\n",
    "        dummies = dummy_df.columns\n",
    "        df = df.merge(dummy_df, how='left', left_index=True, right_index=True)\n",
    "        for dummy in dummies:\n",
    "            df[dummy] = df[dummy] * df[count_col] \n",
    "            #multiplying dummy with Anzahl(todes)Fall so that each dummy column contains number of cases in that category\n",
    "            \n",
    "    daily_output = df.drop(columns='week_no').groupby(['districtId','Meldedatum']).sum()\n",
    "    weekly_output = df.drop(columns='Meldedatum').groupby(['districtId','week_no']).sum()\n",
    "    \n",
    "    return daily_output, weekly_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_infects, weekly_infects = aggr_reports(rki_infect, 'AnzahlFall')\n",
    "daily_deaths, weekly_deaths = aggr_reports(rki_deaths, 'AnzahlTodesfall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rki_daily = pd.merge(daily_infects, daily_deaths, how='outer', \n",
    "                    left_index=True, right_index=True,\n",
    "                    suffixes=('_infected', '_deceased')).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rki_weekly = pd.merge(weekly_infects, weekly_deaths, how='outer', \n",
    "                    left_index=True, right_index=True,\n",
    "                    suffixes=('_infected', '_deceased')).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, make sure that there are no day/weeks skipped in the data due to zero cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = np.unique(rki_raw.districtId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_d = rki_daily.Meldedatum.min()\n",
    "last_d = rki_daily.Meldedatum.max()\n",
    "\n",
    "all_dates = [first_d + dt.timedelta(days=x) for x in range((last_d-first_d).days + 1)]\n",
    "\n",
    "all_combin_d = pd.DataFrame([(dist, day) for dist in districts for day in all_dates], columns=['districtId','Meldedatum'])\n",
    "\n",
    "rki_daily = pd.merge(all_combin_d, rki_daily, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_w = rki_weekly.week_no.min()\n",
    "last_w = rki_weekly.week_no.max()\n",
    "\n",
    "all_weeks = [first_w + x for x in range(last_w-first_w + 1)]\n",
    "\n",
    "all_combin_w = pd.DataFrame([(dist,week) for dist in districts for week in all_weeks],columns=['districtId','week_no'])\n",
    "\n",
    "rki_weekly = pd.merge(all_combin_w, rki_weekly, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in static data for population sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_data = pd.read_csv('processed_static_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "populations = static_data[['districtId','total_population']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add cumulative case numbers and per capita values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulate_and_per_cap(df):\n",
    "    df_ = df.copy()\n",
    "    cols = df.columns[2:]\n",
    "    for col in cols:\n",
    "        df_[col+'_cumul'] = df_.groupby('districtId')[col].cumsum()\n",
    "        \n",
    "    df_ = df_.merge(populations)\n",
    "    cols = ['AnzahlFall', 'AnzahlTodesfall']\n",
    "    cols = cols + [col + '_cumul' for col in cols]\n",
    "    for col in cols:\n",
    "        df_[col+'_per_cap'] = df_[col] / df_['total_population']\n",
    "        \n",
    "    \n",
    "    return df_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rki_weekly = cumulate_and_per_cap(rki_weekly)\n",
    "rki_daily = cumulate_and_per_cap(rki_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rki_weekly.to_csv('rki_weekly.csv',index=False)\n",
    "rki_daily.to_csv('rki_daily.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
