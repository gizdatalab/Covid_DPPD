{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare holiday calenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_provinces = holidays.DE.PROVINCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_dict = {}\n",
    "for province in german_provinces:\n",
    "    holiday_dict[province] = holidays.DE(years=[2019,2020,2021],prov=province)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayern hat einmal normalen Feiertagskalender, und dann noch BYP für protestantische Landkreise... das würde ich jetzt einfach mal ignorieren, und allen bayrischen Landkreise and Maria Himmelfahrt frei geben?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in edge table and mobility volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgetable = pd.read_csv('teralytics_2019_20_edge_table.csv')\n",
    "mobvolume = pd.read_csv('teralytics_2019_20_mobility_per_district_and_day.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datetime variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [edgetable, mobvolume]:\n",
    "    df['date'] = pd.to_datetime(df['date'],format='%Y-%m-%d')\n",
    "    df['week_no'] = df['date'].dt.week\n",
    "\n",
    "    \n",
    "mobvolume['day_of_the_week'] = mobvolume['date'].dt.day_name()\n",
    "#leave the day of the week in this string format for easier daily dummy creation if need be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get provinces from districtIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov_ags_dict = {8:'BW',\n",
    "                 9:'BY',\n",
    "                 11:'BE',\n",
    "                 12:'BB',\n",
    "                 4:'HB',\n",
    "                 2:'HH',\n",
    "                 6:'HE',\n",
    "                 13:'MV',\n",
    "                 3:'NI',\n",
    "                 5:'NW',\n",
    "                 7:'RP',\n",
    "                 10:'SL',\n",
    "                 14:'SN',\n",
    "                 15:'ST',\n",
    "                 1:'SH',\n",
    "                 16:'TH'}\n",
    "\n",
    "mobvolume['province'] = np.floor(mobvolume['districtId'] / 1000).map(prov_ags_dict)\n",
    "#first digits of AGS code for Province"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare workday vs day_off dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobvolume['holiday'] = None\n",
    "for i in mobvolume.index:\n",
    "    mobvolume.holiday.at[i] = mobvolume.date[i] in holiday_dict[mobvolume.province[i]]\n",
    "\n",
    "mobvolume['weekend'] = mobvolume['day_of_the_week'].isin(['Saturday','Sunday'])\n",
    "\n",
    "mobvolume['day_off'] = mobvolume['holiday'] | mobvolume['weekend']\n",
    "\n",
    "mobvolume['workday'] = ~mobvolume['day_off']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate trip counts into workday and day_off columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_sum = []\n",
    "for mobi_type in ['internal','incoming']: #maybe add outgoing as well, but should not matter for district infections\n",
    "    for work in ['workday', 'day_off']:\n",
    "        count_var = 'Count_' + mobi_type\n",
    "        var_name = count_var + '_' + work\n",
    "        variables_to_sum.append(var_name)\n",
    "        mobvolume[var_name] = mobvolume[count_var] * mobvolume[work]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate feature dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobi_volume_features = mobvolume.groupby(['districtId','week_no'])[variables_to_sum].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the incoming infection load. We need a dataframe of infections rate of districts per week. This will be available in the main analysis, I'll load it in here from a downloaded CSV. It's important to note that these are NEW cases per inhabitant and week, not CURRENT cases, as these are unavailable. Since the ratio of new cases to (earlier) current cases can be assumed to be constant, the regression weight/other model fitting should account for this difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will be different in general analysis\n",
    "inf_rates = pd.read_csv('rki_weekly.csv')\n",
    "inf_rates.set_index(['districtId','week_no'],inplace=True)\n",
    "###############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform daily full edge table to weekly edge table without self-loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_internal = edgetable.orig_ags5 == edgetable.dest_ags5\n",
    "weekly_edge_tbl = edgetable[~is_internal].groupby(['week_no', 'orig_ags5', 'dest_ags5']).sum()\n",
    "\n",
    "weekly_edge_tbl.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reset index of infections for easier dataframe merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_rates.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merge infection rates and edge table. Infection rates of trip ORIGINS are added to the edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fefed694a454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m merged_inf_mobi = pd.merge(weekly_edge_tbl, inf_rates, \n\u001b[0m\u001b[0;32m      2\u001b[0m                            \u001b[0mleft_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'week_no'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'orig_ags5'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                            \u001b[0mright_on\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'week_no'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'districtId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                            how='outer')\n\u001b[0;32m      5\u001b[0m \u001b[0mmerged_inf_mobi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'incoming_infected'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerged_inf_mobi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Count'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmerged_inf_mobi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AnzahlFall_per_cap'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "merged_inf_mobi = pd.merge(weekly_edge_tbl, inf_rates, \n",
    "                           left_on = ['week_no','orig_ags5'],\n",
    "                           right_on = ['week_no','districtId'],\n",
    "                           how='outer')\n",
    "merged_inf_mobi['incoming_infected'] = merged_inf_mobi['Count'] * merged_inf_mobi['AnzahlFall_per_cap']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group by trip DESTINATIONS, as this is where the incoming infections come together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "incoming_infections = merged_inf_mobi.groupby(['dest_ags5','week_no'])['incoming_infected'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the districtId, as we no longer need to differentiate between origin and destination districtIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "incoming_infections.rename(columns={'dest_ags5':'districtId'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get structure data for per_head standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be different in general analysis\n",
    "static_data = pd.read_csv('processed_static_data.csv')\n",
    "##########################################\n",
    "populations = static_data[['districtId','total_population']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_features = mobi_volume_features.merge(incoming_infections).merge(populations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Count_internal_workday', 'Count_internal_day_off', \n",
    "            'Count_incoming_workday', 'Count_incoming_day_off', \n",
    "            'incoming_infected']:\n",
    "    var_name = col + '_p_pop'\n",
    "    mobility_features[var_name] = mobility_features[col] / mobility_features['total_population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_features.to_csv('mobility_features.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
